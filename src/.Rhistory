---
title: "Take Home Asssignment 1 (Faizal)"
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
# Case Scenario: University Restaurant Analysis
Problem Description:
A new restaurant has opened in University Town and is collecting anonymised data on student visits. Each record contains basic demographic and academic information, as well as the check-in and check-out times for each visit.
You are tasked to analyze this dataset and help the owner gain deeper insights into their student clientele and identify ways to improve service.
Answer the following questions using the dataset `restaurant.xlsx`. Show your code and interpretations clearly.
```{r packages}
pacman::p_load(tidyverse, readxl, lubridate)
pacman::p_load(tidyverse, readxl, lubridate)
## Import the dataset
```{r import}
## Q1. How many unique students visited the restaurant?
```{r q1}
# Insert your codes here
n_distinct(df3$StudentID)
df3 <- read_excel("../data/restaurant.xlsx")
df3 <- read_excel("../data/restaurant.xlsx")
## Q1. How many unique students visited the restaurant?
```{r q1}
# Insert your codes here
n_distinct(df3$StudentID)
# Ans: There are 99 unique students.
```
## Q2. For each student, calculate the mean latency (in days) between consecutive visits to the restaurant and store your result in a new dataframe called `df_latency`. Consider the number of visits a student must have to calculate latency. Ensure that the dataset is sorted by Checkin time for each student.
```{r q2}
# Insert your codes here
df_latency <- df3 %>%
arrange(StudentID, Checkin) %>%
group_by(StudentID) %>%
mutate(Latency = as.numeric(difftime(Checkin, lag(Checkout), units = "days"))) %>%
select(StudentID, Latency) %>%
filter(!is.na(Latency))
## Q3. Using the mean latencies calculated in Q2, what is the overall average latency across all students? Round your answer to the nearest whole number.
```{r q3}
# Insert your codes here
# Calculate average Latency by StudentID
df_AvgLatency <- df_latency %>%
group_by(StudentID) %>%
summarize(Average_Latency = round(mean(Latency)))
# Compute the overall average Latency based on all Students
overall_average_latency <- mean(df_latency$Latency)
overall_average_latency
#Threshold from Q3, rounded off to the nearest whole number
threshold <- overall_average_latency
student_promotion <- df_AvgLatency %>%
filter(Average_Latency >= threshold) %>%
nrow()
# Insert your codes here
# Join faculty back to df_latency
df_latency_faculty <- df3 %>%
select(StudentID, Faculty) %>%
distinct() %>%
right_join(df_AvgLatency, by = "StudentID")
#Calculate mean latency by faculty
faculty_latency <- df_latency_faculty %>%
group_by(Faculty) %>%
summarise(avg_latency = mean(Average_Latency), group = "drop") %>%
arrange(desc(avg_latency))
# Create the bar chart
bar_pos <- barplot(
faculty_latency$avg_latency,
names.arg = faculty_latency$Faculty,
horiz = TRUE,
col = "steelblue",
xlab = "Mean Latency (days)",
main = "Average Latency by Faculty (days)",
las = 1,
xlim = c(0, 40)
)
# Insert your codes here
# Calculate visit duration (minutes)
df_visits <- df3 %>%
mutate(duration_min = as.numeric(difftime(Checkout, Checkin, units = "mins"))) %>%
filter(Faculty == "Med")
# Data Visualisation
ggplot(df_visits, aes(x = Major, y = duration_min)) +
geom_boxplot(fill = "lightblue") +
coord_flip() +
labs(
title = "Visit Duration by Major (Med Faculty)",
x = "Major",
y = "Duration (minutes)"
) +
theme_minimal()
---
title: "Take Home Assignment 2 (Faizal)"
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
# Case Scenario: Library Usage Analysis
A university library has been tracking visits made by users over the past few months. Each record includes user demographics, visit duration, and number of books borrowed. Your task is to use RFM analysis (Recency, Frequency, and "Monetary" in terms of total books borrowed) to segment users and generate actionable insights for improving library engagement.
Answer the following questions using the dataset `library_visits_THA2.xlsx`. Show your code and interpretations clearly.
```{r package}
pacman::p_load(dplyr, lubridate, readxl, ggplot2)
pacman::p_load(dplyr, lubridate, readxl, ggplot2)
```{r import data}
#Import the library dataset
df <- read_xlsx("../data/library_visits_THA2.xlsx")
str(df)
#Import the library dataset
df <- read_xlsx("../data/library_visits_THA2.xlsx")
str(df)
# Q1. Preprocess the dataset and calculate RFV metrics for each user. Assign 1–3 scores for Recency, Frequency, and Volume using tertiles, and store the results in a new dataframe called `df_rfv`
1. Recency: Days since last visit (assume today is "2025-07-30")
```{r}
# Set reference date
reference_date <- as.Date('2025-07-30')
#Change variables in character format to factor
df <- df %>% mutate_if(is.character,as.factor)
str(df)
# Change Date column to Date object in Year-Month-Day format ("YYYY-MM-DD")
df$Date <- ymd(df$Date)
str(df)
#Check for missing values
sum(is.na(df))
# To identify specific rows with missing values
df[rowSums(is.na(df)) > 0, ]
#Check for duplicates
sum(duplicated(df))
#Compute Recency (days since last visit)
df_recency <- df %>%
group_by(UserID) %>%
summarise(Recency = as.numeric(reference_date - max(Date)))
#Compute Frequency (number of visits per customer)
df_frequency <- df %>%
group_by(UserID) %>%
summarise(Frequency = n())
#Compute Volume per customer
df_volume <- df %>%
group_by(UserID) %>%
summarise(Volume = sum(BookBorrowed, na.rm = TRUE))
#Merge all three metrics into a single dataframe
df_rfv <- df_recency %>%
inner_join(df_frequency, by = "UserID") %>%
inner_join(df_volume, by = "UserID")
#Assign tertiles-based scores (1, 2, 3)
df_rfv <- df_rfv %>%
mutate(Recency_Score = ntile(Recency, 3),
Frequency_Score = ntile(Frequency, 3),
Volume_Score = ntile(Volume, 3)
)
#Adjust Recency Score so that lower recency gets higher score
df_rfv$Recency_Score <- 4 - df_rfv$Recency_Score  # Convert 1→3, 2→2, 3→1
#Adjust Recency Score so that lower recency gets higher score
df_rfv$Recency_Score <- 4 - df_rfv$Recency_Score  # Convert 1→3, 2→2, 3→1
# Q2. Based on RFV scores, segment users from `df_rfv` into the following 6 categories based on the order listed below and report the number of users in each category:
* Avid Readers: R: 3, F: 3, V: 3
```{r}
# Segments are assigned hierarchically in the order listed to avoid overlap
#Assign customer segments based on RFD scores
df_rfv <- df_rfv %>%
mutate(
Segment = case_when(
Recency_Score >= 3 & Frequency_Score >= 3 & Volume_Score >= 3 ~ "Avid Readers",
Recency_Score >= 2 & Frequency_Score >= 2 & Frequency_Score <= 3 & Volume_Score >= 2 & Volume_Score <= 3 ~ "Consistent Borrowers",
Recency_Score == 3 & Frequency_Score <= 2 & Volume_Score <= 2 ~ "Newcomers",
Recency_Score <= 2 & Frequency_Score >= 2 & Volume_Score >= 2 ~ "At-Risk Users",
Recency_Score >= 1 & Recency_Score <= 2 & Frequency_Score >= 1 & Frequency_Score <= 2 &
Volume_Score >= 1 & Volume_Score <= 2 ~ "Inactive",
TRUE ~ "Others"
)
)
table(df_rfv$Segment)
# You should get this output:
# At-Risk Users         Avid Readers Consistent Borrowers             Inactive        #            45                   44                  140                  147        #     Newcomers               Others
#            33                   45
```
# Q3. Visualise the RFV segments using a bar chart and interpret the visualisation. Provide your interpretation in at least 30 words.
```{r}
table(df_rfv$Segment)
# Segments are assigned hierarchically in the order listed to avoid overlap
#Assign customer segments based on RFD scores
df_rfv <- df_rfv %>%
mutate(
Segment = case_when(
Recency_Score >= 3 & Frequency_Score >= 3 & Volume_Score >= 3 ~ "Avid Readers",
Recency_Score >= 2 & Frequency_Score >= 2 & Frequency_Score <= 3 & Volume_Score >= 2 & Volume_Score <= 3 ~ "Consistent Borrowers",
Recency_Score == 3 & Frequency_Score <= 2 & Volume_Score <= 2 ~ "Newcomers",
Recency_Score <= 2 & Frequency_Score >= 2 & Volume_Score >= 2 ~ "At-Risk Users",
Recency_Score >= 1 & Recency_Score <= 2 & Frequency_Score >= 1 & Frequency_Score <= 2 &
Volume_Score >= 1 & Volume_Score <= 2 ~ "Inactive",
TRUE ~ "Others"
)
)
table(df_rfv$Segment)
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(dplyr, lubridate, readxl, ggplot2)
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(dplyr, lubridate, readxl, ggplot2)
#Import the library dataset
df <- read_xlsx("../data/library_visits_THA2.xlsx")
str(df)
# Set reference date
reference_date <- as.Date('2025-07-30')
#Change variables in character format to factor
df <- df %>% mutate_if(is.character,as.factor)
str(df)
# Change Date column to Date object in Year-Month-Day format ("YYYY-MM-DD")
df$Date <- ymd(df$Date)
str(df)
#Check for missing values
sum(is.na(df))
# To identify specific rows with missing values
df[rowSums(is.na(df)) > 0, ]
#Check for duplicates
sum(duplicated(df))
#Compute Recency (days since last visit)
df_recency <- df %>%
group_by(UserID) %>%
summarise(Recency = as.numeric(reference_date - max(Date)))
#Compute Frequency (number of visits per customer)
df_frequency <- df %>%
group_by(UserID) %>%
summarise(Frequency = n())
#Compute Volume per customer
df_volume <- df %>%
group_by(UserID) %>%
summarise(Volume = sum(BookBorrowed, na.rm = TRUE))
#Merge all three metrics into a single dataframe
df_rfv <- df_recency %>%
inner_join(df_frequency, by = "UserID") %>%
inner_join(df_volume, by = "UserID")
#Assign tertiles-based scores (1, 2, 3)
df_rfv <- df_rfv %>%
mutate(Recency_Score = ntile(Recency, 3),
Frequency_Score = ntile(Frequency, 3),
Volume_Score = ntile(Volume, 3)
)
#Adjust Recency Score so that lower recency gets higher score
df_rfv$Recency_Score <- 4 - df_rfv$Recency_Score  # Convert 1→3, 2→2, 3→1
# Segments are assigned hierarchically in the order listed to avoid overlap
#Assign customer segments based on RFD scores
df_rfv <- df_rfv %>%
mutate(
Segment = case_when(
Recency_Score >= 3 & Frequency_Score >= 3 & Volume_Score >= 3 ~ "Avid Readers",
Recency_Score >= 2 & Frequency_Score >= 2 & Frequency_Score <= 3 & Volume_Score >= 2 & Volume_Score <= 3 ~ "Consistent Borrowers",
Recency_Score == 3 & Frequency_Score <= 2 & Volume_Score <= 2 ~ "Newcomers",
Recency_Score <= 2 & Frequency_Score >= 2 & Volume_Score >= 2 ~ "At-Risk Users",
Recency_Score >= 1 & Recency_Score <= 2 & Frequency_Score >= 1 & Frequency_Score <= 2 &
Volume_Score >= 1 & Volume_Score <= 2 ~ "Inactive",
TRUE ~ "Others"
)
)
table(df_rfv$Segment)
order <- c("Avid Readers", "Consistent Borrowers", "Newcomers", "At-Risk Users", "Inactive", "Others")
df_rfv$Segment <- factor(df_rfv$Segment, levels = order)
ggplot(df_rfv, aes(x = Segment, fill = Segment)) +
geom_bar() +
labs(title = "Customer Segmentation Based on RFV",
x = "Customer Segment",
y = "User Count") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Filter "Inactive" group
df_inactive <- df_rfv %>% filter(Segment == "Inactive")
df <- df %>%
mutate(Age_group = case_when(
Age <= 25 ~ "<=25",
Age <= 35 ~ "26-35",
Age <= 50 ~ "36-50",
Age <= 65 ~ "51-65",
TRUE      ~ "66+"
))
df <- df %>%
mutate(Duration_group = case_when(
Duration <= 60 ~ "<=60",
Duration <= 120 ~ "61-120",
Duration <= 180 ~ "121-180",
TRUE      ~ ">=181"
)) %>%
mutate(Duration_group= factor(Duration_group, levels= c("<=60", "61-120", "121-180", ">=181")))
# Prepare demographic data (based on most recent visit per user)
df_demo <- df %>%
arrange(UserID, desc(Date)) %>%
group_by(UserID) %>%
slice(1) %>%
ungroup() %>%
select(UserID, Age_group, Duration_group)
# merge with segments from df_inactive
df_inactive_demo <- df_inactive %>%
left_join(df_demo, by = "UserID")
# Create bar chart of df_inactive_demo by Age group:
ggplot(df_inactive_demo, aes(x = Age_group, fill = Age_group)) +
geom_bar() +
labs(title = "Inactive Users by Age Group",
x = "Age Group",
y = "Inactive User Count") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Create bar chart of df_inactive_demo by Duration group:
ggplot(df_inactive_demo, aes(x = Duration_group, fill = Duration_group)) +
geom_bar() +
labs(title = "Inactive Users by Duration Group",
x = "Duration Group",
y = "Inactive User Count") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
